{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqCzUoUC85vP"
   },
   "source": [
    "# Chage the annotations format to be compatible with YOLOv11-OBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pickleshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1055,
     "status": "ok",
     "timestamp": 1751009909991,
     "user": {
      "displayName": "LUIS GUZMAN GARRIDO CALVO",
      "userId": "15891220556883174323"
     },
     "user_tz": -120
    },
    "id": "D9o2UJJn9iOp",
    "outputId": "c6216a54-7eb5-4fd6-8e1e-6a7ca3e618a0"
   },
   "outputs": [],
   "source": [
    "cd /workspace/samgtgenerate2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 99496,
     "status": "ok",
     "timestamp": 1751010009488,
     "user": {
      "displayName": "LUIS GUZMAN GARRIDO CALVO",
      "userId": "15891220556883174323"
     },
     "user_tz": -120
    },
    "id": "uwngdsak-JTT",
    "outputId": "16e46746-1f1e-4500-de90-afd5415f689c"
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use segment2YOLOGT to create masks of the annotations using SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 457834,
     "status": "ok",
     "timestamp": 1751010467381,
     "user": {
      "displayName": "LUIS GUZMAN GARRIDO CALVO",
      "userId": "15891220556883174323"
     },
     "user_tz": -120
    },
    "id": "WaUhzyy282i1",
    "outputId": "01d6c24b-93f0-48cc-fe4d-fe7488370a31"
   },
   "outputs": [],
   "source": [
    "!python segment2YOLOGT.py -i /workspace/C_Split_80_10_10/training/images -x /workspace/C_Split_80_10_10/training/Annotations -o C_80_10_10_train --ckp sam_vit_h_4b8939.pth --ln --classes /workspace/samgtgenerate2025/XML2Img-classes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform polygons generated with SAM to OBB annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60s43FFKDdPf"
   },
   "source": [
    "YOLOv11-OBB uses annotations with this structure: class_index x1 y1 x2 y2 x3 y3 x4 y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1751011502859,
     "user": {
      "displayName": "LUIS GUZMAN GARRIDO CALVO",
      "userId": "15891220556883174323"
     },
     "user_tz": -120
    },
    "id": "jqX9aYynD0-Q"
   },
   "outputs": [],
   "source": [
    "#CODE THAT TRANSFORMS POLYGONS GENERATED WITH SAM TO OBB ANNOTATIONS\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def polygon_to_obb(line, img_width, img_height):\n",
    "    # Split input line into class id + polygon coordinates\n",
    "    data = line.strip().split()\n",
    "    if len(data) < 10:  # must have class id + at least 4 points\n",
    "        return None  \n",
    "    \n",
    "    try:\n",
    "        class_id = int(data[0])\n",
    "        coords = list(map(float, data[1:]))\n",
    "        if len(coords) % 2 != 0:  # coordinates must be in pairs\n",
    "            return None  \n",
    "\n",
    "        # Convert to (N,2) array and scale from normalized [0,1] → pixels\n",
    "        coords = np.array(coords, dtype=np.float32).reshape(-1, 2)\n",
    "        coords[:, 0] *= img_width\n",
    "        coords[:, 1] *= img_height\n",
    "\n",
    "        # Fit minimum-area rectangle around polygon\n",
    "        cnt = coords.reshape(-1, 1, 2)\n",
    "        rect = cv2.minAreaRect(cnt)\n",
    "        box = cv2.boxPoints(rect)\n",
    "\n",
    "        # Clip to image bounds and normalize back to [0,1]\n",
    "        box = np.clip(box, [0, 0], [img_width, img_height])\n",
    "        box[:, 0] /= img_width\n",
    "        box[:, 1] /= img_height\n",
    "\n",
    "        # Return as YOLO-style string: class_id + 8 coords\n",
    "        flattened = box.flatten()\n",
    "        return f\"{class_id} \" + \" \".join(f\"{x:.6f}\" for x in flattened)\n",
    "    except Exception as e:\n",
    "        return None  \n",
    "\n",
    "\n",
    "def convert_folder(input_dir, output_dir, img_width, img_height):\n",
    "    # Create output directory if it doesn’t exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through all annotation files\n",
    "    for filename in sorted(os.listdir(input_dir)):\n",
    "        if not filename.endswith('.txt'):\n",
    "            continue\n",
    "\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        # Read input annotation and write converted OBB annotations\n",
    "        with open(input_path, 'r') as infile, open(output_path, 'w') as outfile:\n",
    "            count = 0\n",
    "            for line in infile:\n",
    "                count += 1\n",
    "                obb_line = polygon_to_obb(line, img_width, img_height)\n",
    "                if obb_line:\n",
    "                    outfile.write(obb_line + '\\n')\n",
    "\n",
    "            # Log how many lines were processed in the file\n",
    "            print(f\"{filename}: {count} vehicles processed.\")\n",
    "\n",
    "# MAIN\n",
    "input_dir = '/workspace/C_polygons_labels/labels/' \n",
    "output_dir = '/workspace/C_polygons_labels/OBB/'      \n",
    "img_width = 3.840                 \n",
    "img_height = 2.160                    \n",
    "convert_folder(input_dir, output_dir, img_width, img_height)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPFNHPDGZ6AdZ8HL7Vh/Iuw",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
